<<<<<<< HEAD

\documentclass[10pt,journal,compsoc]{IEEEtran}



% *** CITATION PACKAGES ***
%
\ifCLASSOPTIONcompsoc
  % IEEE Computer Society needs nocompress option
  % requires cite.sty v4.0 or later (November 2003)
  \usepackage[nocompress]{cite}
\else
  % normal IEEE
  \usepackage{cite}
\fi


% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
   \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
   \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi


\usepackage[ruled]{algorithm2e}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{algorithmic}
\usepackage{array}
\usepackage{verbatim} % multple line comments

% *** SUBFIGURE PACKAGES ***
\ifCLASSOPTIONcompsoc
  \usepackage[caption=false,font=footnotesize,labelfont=sf,textfont=sf]{subfig}
\else
  \usepackage[caption=false,font=footnotesize]{subfig}
\fi


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

\graphicspath{{images/}}

\begin{document}

\title{Content-Preserving Image Stitching with the Regular Boundary Constraint} % title must contain stitching


\author{Yun Zhang,
        Yu-Kun Lai,~\IEEEmembership{Member,~IEEE,}
        and~Fang-Lue Zhang,~\IEEEmembership{Member,~IEEE}% <-this % stops a space
\IEEEcompsocitemizethanks{\IEEEcompsocthanksitem Yun Zhang is with the Institute of Zhejiang Radio and TV Technology, Communication University of Zhejiang, Hangzhou, China, 310018.\protect\\
E-mail: zhangyun@cuz.edu.cn
\IEEEcompsocthanksitem  Yu-Kun Lai is with the School of Computer Science and Informatics, Cardiff University, Wales, UK,  CF24 3AA.\protect\\
E-mail: Yukun.Lai@cs.cardiff.ac.uk
\IEEEcompsocthanksitem Fang-Lue Zhang is with the School of Engineering and Computer Science, Victoria University of Wellington, New Zealand.\protect\\
E-mail: fanglue.zhang@ecs.vuw.ac.nz
}% <-this % stops an unwanted space
\thanks{}}

% The paper headers
\markboth{}%
{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for Computer Society Journals}


\IEEEtitleabstractindextext{%
\begin{abstract}

This paper proposes a content-preserving stitching with the regular boundary constraint, which aims to rectangling the panorama images with irregular boundary, while avoiding unexpected distortions in the warping-based processes.
In our method, the traditional stitching is improved by considering the regular boundary constraint, and the stitching process is configured to be a two-step global optimization which can be efficiently solved.
We first conduct stitching by traditional warping-based optimization, and take the warped meshes as initial conditions of the final stitching.
Then, we obtain the irregular boundary from the warped meshes by the polygon boolean operations, and construct piecewise rectangular boundary by analyzing and sorting vertices on the irregular boundary.
With the piecewise rectangular boundary constraint, we proceed the second step global optimization which incorporates straight line preserving and regular boundary constraints into the image stitching framework.
We further conduct iterative optimization to obtain optimal piecewise rectangular boundary, thus can make the panoramic boundary be close to rectangle as much as possible, while reducing unwanted distortions.
We further extend our method to panoramic videos and sefie photography, which integrate the temporal coherence and portrait-preserving into the optimization.
Experiments show that our method can efficiently produce visual-pleasing results with regular boundaries, unnoticeable distortions.
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
content-preserving, panorama, irregular boundary, piecewise rectangular, warping.
\end{IEEEkeywords}}


% make the title area
\maketitle


\IEEEdisplaynontitleabstractindextext

\IEEEpeerreviewmaketitle


\IEEEraisesectionheading{\section{INTRODUCTION}\label{sec:introduction}}

\begin{comment}
\IEEEPARstart{I}{mage} stitching is a well-studied problem, which has been successfully applied to smart phones and portable cameras, and people can easily take panorama images simply by moving cameras.
Panorama images are popular due to the wide viewing and immersion experiences, and rise of VR further expands the application of stitching techniques.
Due to the casual moving of hand-held cameras, after feature alignment, most stitching results have irregular boundaries. For better viewing, the final results generated by our cameras are usually cropped by rectangular windows.
Although simple and effective, the cropping-based method can not preserve complete content of stitched panorama, thus may reduce the impression of wide angle photography.
In order to produce panorama images with regular boundaries, image completion techniques~\cite{journals/mta/YenYC17,journals/tog/BarnesSFG09} are used to synthesize the missing region in the bounding box. However, these methods are not stable, and may fail to synthesize semantic contents in images.

To generate panorama images with irregular boundaries, He et al.~\cite{journals/tog/HeC013} proposed a warping based method to rectangling panorama images, which can stably produce visual-pleasing panorama images with rectangular boundaries.
Although useful and effective, their method treats stitching and rectangling as two individual processes, thus still suffer from some problems: (1) The rectangling and stitching may affect each other, thus it is hard to get optimized results; (2) It is hard to place grid meshes in irregular input panoramas, and boundary meshes may contain small holes; (3) The warping-based method will produce large distortion and destroy the feature alignment, when the scene is not completely shot.
Actually, the warping-based rectangling~\cite{journals/tog/HeC013} are effective only when the gap between the rectangle and the irregular boundary is small, and the content is enough to make a rectangle panorama with unnoticeable distortion, which limits the range of application.
In practice, users tend to shot images with hand-held cameras in a casual manner, and direct retangling irregular boundaries may introduce too much distortions, which degrades the visual effects of panorama.
\end{comment}

\IEEEPARstart{T}{he} rapid recent advances in digital visual media mean that the public now capture and produce high-quality images and videos, which has promoted the computer graphics applications that utilise visual data captured by ordinary users. Image/video panorama  is one of these successful applications. With the integrated panorama module in their smart phones and portable cameras, people can easily take a panoramic photos simply by moving cameras. It is also the most feasible way to get virtual reality content for immersive vision experiences. However, unlike the well calibrated images captured by professional devices with a camera array, the intrinsic and extrinsic parameters of the images captured by consumer-level devices are difficult to estimate. Thus, a robust image stitching method which directly stitches using the visual content is much more important for the applications designed for the ordinary users,

Recently, a lot of progresses have been made in image stitching. However, due to the casual motion of the hand-held cameras, after feature alignment, most stitching results by previous methods have irregular boundaries. To display the full panorama in common screens, or generate free-viewpoint photos from one part of the whole scene recorded by the image collection, we can only show them in rectangular windows. A simple and direct method is cropping, but it will lose important content of stitched panorama, thus may reduce the impression of wide angle photography. In order to produce panorama images with rectangular boundaries, image completion techniques~\cite{journals/mta/YenYC17, journals/tog/BarnesSFG09} are used to synthesise the missing region in the panorama's bounding box. However, these methods are not stable, and may fail when there need to be semantic meaningful objects. He et al.~\cite{journals/tog/HeC013} proposed a warping based method to rectangling panorama images, which can stably produce visual-pleasing panorama images with rectangular boundaries. But their method suffers from the following problems:
(1) The stitching and rectangling are two separated processes, so the latter rectangling step may twist the optimized stitching result, making it hard to get an optimal rectangle panorama.
(2) When placing grid meshes in stitched irregular panoramas for rectangling, boundary meshes may contain small holes, see Fig.~\ref{fig:holes_he}(c).
(3) The warping-based method will produce large distortion and destroy the feature alignment, when the scene is not completely shot.
Thus, when the gap between the rectangular boundary and irregular panorama boundary is large, or there are holes which are difficult for completion and warping methods to fill, there need to be a better approach to create the panorama with regular boundaries while avoiding distortions.

In this paper, we propose a content-preserving image stitching, which aims to regularize the boundary of stitched panorama, and preserve as much as possible content in a  rectangular cropping window.
Our method can also be applied in videos and selfie photography, and can produce panorama video and selfie with regular boundary.
Similar to He et al.~\cite{journals/tog/HeC013}, the process of generating panorama images with rectangular boundaries is termed as ``rectangling'' . Our method is based on the following observations:
(1) Rectangling and stitching are tightly related, and combination of the two processes may help to produce better rectangling panorama in a content-aware manner.
(2) The aim of panorama rectangling is to preserve as much as possible image content in a rectangular window while avoiding unexpected distortion, thus the irregular boundary should not be simply optimized to be a single rectangle, but piecewise rectangle, see Fig.~\ref{fig:piecewise-process}(c).

Our method works well in a variety of cases, and can produce visual-pleasing results with no user interactions. The key idea of our algorithm is a two-step optimization. We first stitch images using traditional method to get irregular boundaries, and then we extract and outer boundary and analyze the boundary constraint, finally we globally optimize the mesh to get stitching results with regular boundaries.
In the first step, we apply image stitching with the global similarity prior~\cite{conf/eccv/ChenC16}, and get the boundary vertices by the polygon boolean union operation.
In the second step, We extract the irregular boundary by the polygon boolean operations, and then construct the regular boundary constraint by analyzing the vertices and intersections in the irregular boundary.
Finally, we design a global optimization which takes into account the regular boundary, shape preserving, straight lines, global similarity constraints.
When the target boundary is simply a rectangle, see Fig.~\ref{fig:pipeline}, the panorama image is directly obtained by solving the global optimization.
For panorama shot by freely moving cameras, the target boundary can not simply represented by a rectangle, see Fig.~\ref{fig:piecewise-process}, and we propose piecewise rectangle to represent the regular boundary.
With the new boundary condition, we get the panorama by solving the optimization and warping. Then we iteratively combine boundary segments connected by $step$(see Fig.~\ref{fig:pipeline}(f)), and finally we get panorama image with optimal piecewise rectangular boundary. Our final result can help users easily crop panorama while preserving as much as possible content in the cropping window, while avoiding unwanted distortions and enhancing the panorama viewing experiences.

Contributions of this paper are as follows:
\begin{itemize}
   \item We propose a global optimization to solve the irregular boundary problem in traditional stitching framework by considering the regular boundary constraint, and further apply our method to panoramic selfie and videos.
   \item We propose a piecewise rectangling scheme to make the panoramic boundary close to a rectangle as much as possible, while avoid unexpected distortions.
\end{itemize}

 \section{RELATED WORK}
In this section, we briefly review the most related works.

\textbf{image stitching}.
Image stitching aims to create seamless and natural photo-mosaics, and a comprehensive survey of image stitching algorithms is given in~\cite{journals/ftcgv/Szeliski06}.
Brown et al.~\cite{journals/ijcv/BrownL07} proposed fully automatic panoramic image stitching, and align multiple images by a single homography. Their method is effective under assumption that camera only rotates around its optical center, images are shot from the same viewpoint and the scenes are nearly planar. However, for images shot by hand-held cameras always contain parallax, which limits the application of their method.
Given the limitation of single homegraphy, Gao et al.~\cite{conf/CVPR/GaoKB11} proposed to use two homographies to perform nonlinear alignment, when the scene is modeled by dominant distant and ground planes. However, their method is only effective when there is no local perspective variations.
For better performance in image alignment, Zaragoza et al.~\cite{journals/pami/ZaragozaCTBS14} proposed as-projective-as-possible(APAP) warps based on moving DLT, and can seamlessly align images with different projective models. Their method can achieve globally perspective, while allowing local non-projective deviations, thus can deal with some challenging cases. Now APAP~\cite{journals/pami/ZaragozaCTBS14}  has been widely applied for its excellent performance in accurate alignment. In this paper, we also apply APAP for image alignment in stitching.
Based on the accurate alignment in APAP~\cite{journals/pami/ZaragozaCTBS14}, Lin et al.~\cite{conf/CVPR/LinPRA15} combined local homography and global similarity transformation to achieve more continuous and smooth stitching, and provided more natural panorama with less visible parallax and perspective distortion.
Li et al.~\cite{conf/ICCV/LiY0Q15} proposed dual-feature warping-based model by combining keypoints and line segment features. However, the 2D model proposed in this paper cannot handle large parallax and depth variation, and it is difficult to determine the line correspondences in images with large parallax.
For natural warping in stitching, Chang et al.~\cite{conf/cvpr/ChangSC14} proposed a parametric warp which combines projective and similarity transformation. By combining APAP~\cite{journals/pami/ZaragozaCTBS14}, their method can provide more accurate alignment, less distortion.
Chen et al.~\cite{conf/eccv/ChenC16} proposed natural image stitching with global similarity prior to reduce distortion while keep good alignment.
To preserve global similarity, they further proposed schemes to select proper scale and rotation for more natural stitching results.
To stitch images with large parallax, Zhang et al.~\cite{conf/cvpr/ZhangL14a} proposed local stitching method, which is based on the observation that overlapping regions do not need to be aligned perfectly.
Lin et al.~\cite{conf/eccv/LinJCDL16} proposed a seam-guided local alignment, and optimal local alignment is guided by the seam estimation.
In their method, salient curve and line structures are preserved by local and non-local similarity constraint.
Very recently, Li et al.~\cite{journals/tmm/LiWLZZ18} proposed robust elastic warping for parallax-tolerant image stitching. To ensure a robust alignment, they proposed a Bayesian model to remove incorrect local matches.
He et al.~\cite{journals/tog/HeC013} proposed a content-aware warping to produce rectangular images from stitched panorama.  Their method is effective to rectangling irregular boundaries caused by projections and casual camera movements. However, their two-step warping strategy separates stitching and rectangling process, which can not ensure an optimal solution, and their method can not process panoramic scenes that are not completely shot.
Inspired by~\cite{journals/tog/HeC013}, We incorporate rectangling into the stitching framework, and construct global optimization to get rectangular panoramic images.
We also proposed solutions to deal with challenging cases, such as images that are not completely shot, and apply our method to panoramic videos and selfies.

\textbf{video stitching}.
Compared with image stitching, video stitching is much more difficult, due to the camera motion, dynamic foreground and large parallax.
For static camera settings, such as multi-camera surveillance~\cite{journals/sensors/HeY16,journals/itiis/YinLWLZ14},  videos from different cameras are aligned only once, and the main challenge is to avoid ghosting and artifacts caused by moving objects.
For moving cameras with relative fixed positions, such as camera arrays fixed on the rig~\cite{journals/cgf/PerazziSZKWWG15}, cameras can be pre-calibrated for global stitching of videos, and spatia-temporally coherent warping, minimal distortion are the main challenges due to the motion and parallax.
Google streetview~\cite{journals/computer/AnguelovDFFLLOVW10} also applies moving camera arrays for street view capture and panorama generation.
To generate high-quality panorama videos, for videos captures by camera arrays fixed on a rig, Zhu et al.~\cite{journals/tip/ZhuLWZMLH18} proposed realtime panorama video blending.
Meng et al.~\cite{conf/mm/MengWL15} proposed multi-UAV surveillance system that supports real-time video stitching.
Recently, many researchers focus on stitching algorithm for videos shot by multiple hand-held cameras.
El-Saban et al.~\cite{conf/icip/El-SabanEKR11} proposed optimal seam selection blending for fast video stitching, however, they do not consider video stabilization.
Lin et al.~\cite{journals/cgf/LinLCZ16} firstly proposed robust framework stitch videos from moving hand-held cameras, which incorporates stabilization and stitching into a unified framework.
Guo et al. and Nei et al.~\cite{journals/tip/GuoLHZZG16,journals/tip/NieSZSL18} further improve the performance of  jointly video stabilization and stitching framework.
Their main contributions include: estimation of inter motions between cameras and intra motions in a video; common background identification for multiple input videos.
In this paper, we extend our content-preserving image stitching to videos that are captured from unstructured camera arrays\cite{journals/cgf/PerazziSZKWWG15}.

\begin{figure*}[t] %% htbp
  \centering
  \includegraphics[width=1.0\textwidth]{flowchart-new}
  \caption{Pipeline of  our stitching with regular boundary. (a) Input images. (b) initial stitching with irregular boundaries. (c) mesh of initial stitching. (d) outer boundary extracted by polygon boolean extraction. (e) irregular boundary extraction. (f) target regular boundary. (g) mesh of piecewise rectangling. (h) our result. (i) He et al.'s rectangular panorama.} \label{fig:pipeline}
\end{figure*}

 \section{OVERVIEW}
Fig.~\ref{fig:pipeline} gives the pipeline of our content-preserving stitching.
The input to our approach is a number of images with content overlaps, and the goal is to obtain panorama images with regular boundaries by our content-preserving stitching.
We first perform traditional image stitching, and extract the irregular boundary by polygon boolean operations.  Then, we further analyze and sort vertices on the irregular boundary, and construct the piecewise rectangular boundary constraints.
With the boundary constraint above, we obtain the piecewise rectangling result by iteratively solving global optimizations.
We place quad-mesh on each image, and construct energy functions with constraints on the mesh. After optimization, the stitching results are rendered by image warping and blending.
The core of our approach is the unified optimization framework that combines image stitching and rectangling, which contains following steps:

%Similar to~\cite{journals/tog/HeC013}, we also call this process "rectangling"~\cite{journals/tog/HeC013}, which contains following steps.
\textbf{Preprocessing}.
In this step, we first calculate the image match graph using the method proposed in~\cite{journals/ijcv/BrownL07}, and images that are connected in the match graph are aligned to be panoramas. This automatic match process allows stitching with complex image overlaps.
For straight line and global feature preserving, we detect lines in all images using fast line segment detector~\cite{journals/pami/GioiJMR10}.

\textbf{Initial image stitching}.
The goal of this step is to initialize our content-preserving stitching, and our regular boundary constraints are based on the analysis of warped meshes after stitching. The stitching strategy in this step is also applied in our global optimization which combines stitching and rectangling.
We apply APAP~\cite{journals/pami/ZaragozaCTBS14} for accurate feature alignment.
Inspired by~\cite{conf/eccv/ChenC16}, we also add a global similarity term for more natural stitching, and the distortion is minimized globally.

\textbf{Irregular boundary extraction}.
After the initial image stitching, we extract the contour of each warped mesh, and get the irregular boundary by the polygon boolean Union operation.
Then, we analyze and sort vertices and intersections on the irregular boundary.
Finally, we set the target rectangular boundary constraints for our piecewise rectangular stitching.

 \textbf{Piecewise rectangular stitching}
With the rectangular boundary constraints above, we construct energy optimization which contains image stitching and regular boundary constraint.
After minimizing the energy function, we get the stitching result by warping and blending.
We iteratively optimize the stitching result by combining boundary segments near the cuts of each direction.

\section{Content-preserving image stitching}
 In this step, we propose a global optimization which aims to generate panoramas with regular boundaries in the image stitching framework.
 The optimization consists of the following constraints: feature alignment, shape preserving, global similarity preserving, straight lines preserving and regular boundary constraints.
With the optimized vertices, we warp the mesh by texture mapping, and remove the seams by multi-banded blending.
For scenes that are not completely shot, our piecewise rectangular stitching can iteratively optimize the target panorama boundary, and make the shape of our panorama be close to a rectangle as mush as possible, while avoiding the unwanted distortions.

 \subsection{Initial image stitching}
 \label{sec:Initial image stitching}
 In this step, images are stitched using traditional method, and the irregular boundary of warped mesh are initial conditions for our piecewise rectangular stitching.
 Actually, when the gap between the irregular boundary and the target rectangular boundary is too large, it will be difficult or even impossible for rectangling with unnoticeable distortion.
 Inspired by ~\cite{conf/eccv/ChenC16}, we stitch images using the global similarity prior to generate more natural panoramas without too much distortions and limit of field of view.
 Like previous methods, image stitching is performed by mesh-based image warping.
 Let $V_i$ and $E_i$ be the vertices and edges in image $I_i$, we aim to get deformed vertices $V$ by minimizing the energy function $\Phi(V)$, which contains following terms:
Feature alignment, local shape and global similarity preserving.

\textbf{Feature Alignment}.
This term aims to align matched images by preserving the feature correspondences between them.
Given the good performance in piecewise alignment, we apply APAP~\cite{journals/pami/ZaragozaCTBS14} for feature alignment, and the feature alignment constraint is defined as follows.
\begin{equation} \label{equ:feature_align}
\begin{split}
    \phi_a(\mathbf{V}) = \sum\limits_{i=1}^N\sum\limits_{(i, j)\in G}\sum\limits_{p^{ij}_m \in M_{ij}} \
    ||\mathbf{V}^{ij}_{pq} \cdot  \mathbf{\Omega}^{ij}_{pq} - \mathbf{\widetilde{V}}^{ij}_{pq} \cdot  \mathbf{\widetilde{\Omega}}^{ij}_{pq}||^2,
\end{split}
\end{equation}
where $G$ refers to the image match graph which determine the matched image pair.
$p_{ij}^m$ represents a pair of matched feature points in image $i$ and $j$ respectively, and $M_{ij}$ is the image matching set.
Since the constraints are imposed on vertices of the mesh, we employ the bilinear coordinates represent matched feature points as the interpolation of four vertices of a quad grid
$p_{ij}^m=\mathbf{V}^{ij}_{pq} \cdot  \mathbf{\Omega}^{ij}_{pq}$ , where $\mathbf{V}^{ij}_{pq}=[V^{ij}_{p,q},V^{ij}_{p+1,q},V^{ij}_{p+1,q+1},V^{ij}_{p,q+1}]$ and $\mathbf{\Omega}^{ij}_{pq}=[\omega^{ij}_{p,q},\omega^{ij}_{p+1,q},\omega^{ij}_{p+1,q+1},\omega^{ij}_{p,q+1}]$.

\textbf{Shape consistency}.
This term aims to ensure that each quad grid in the mesh can underdo a similar transform and do not distort too much.
we use the shape preserving term defined in~\cite{journals/tog/LiuYT013}, which split each grid into two triangles and applies the method in as-rigid-as-possible warping~\cite{journals/tog/IgarashiMH05}.

\begin{equation} \label{equ:shape_preserving}
\begin{split}
    \phi_s(\mathbf{V}) = \sum\limits_{i=1}^N\sum\limits_{j} \
    ||V_j^i -V_1^i-\xi \mathbf{R}(V_0^i -V_1^i)||^2, \\
   \textbf{where}\quad \mathbf{R}=\left[\begin{array}{cc}cos\theta&sin\theta \\-sin\theta&cos\theta\end{array}\right], \\
    \textbf{and} \quad\xi=||V_j^i -V_1^i||/||V_0^i -V_1^i||.
\end{split}
\end{equation}

In Equ.~\ref{equ:shape_preserving}, $\theta$ refers to the angle formed by moving segments From $V_1V_0$ to $V_1V$, when the direction is anticlockwise $\theta=90^{\circ}$, and $\theta=-90^{\circ}$ for the clockwise direction. In our implementation, $V_j^i$ refers to the top-left vertex of all quads in the image mesh, $V_0^i$ and $V_1^i$ are the neighboring vertices of $V_j^i$ in a triangle.

\textbf{Global similarity}.
We use the global similarity term proposed in~\cite{conf/eccv/ChenC16}, which is important to preserve the naturalness of the panorama images.
We first set a reference image $I_0$ and its desired rotation $r_0$,  then for each image desired scale $s_i$ and rotation $r_i$ with respect to $I_0$ are calculated, see details in~\cite{conf/eccv/ChenC16}. The global similarity term is defined as
\begin{equation} \label{equ:global_similarity}
\begin{split}
    \phi_g(\mathbf{V}) = \sum\limits_{i=1}^N\sum\limits_{e^i_j \in \mathbf{E}_i} \alpha(e^i_j)[&|| c(e^i_j)-s_i cos\theta_i ||^2+\\
    &|| s(e^i_j)-s_i sin\theta_i ||^2],
\end{split}
\end{equation}

In Equ. \ref{equ:global_similarity}, $c(e^i_j)$ and $s(e^i_j)$ refer to the coefficients of  grid edges for similarity transform in $x$ and $y$ directions, see details in~\cite{journals/jgtools/IgarashiI09}. $\alpha(e^i_j)$ is the weight to assign more importance to the edge in the overlapping region, while less in other area, in order to keep accurate alignment and preserve the naturalness, and it is defined as
\begin{equation} \label{equ:global_weight}
\begin{split}
    \alpha(e^i_j)= \cdot \frac{\sum\limits_{q_m\in Q(e^i_j)}Min(d_{cen}(q_m, \Psi_i))}{\sqrt {W_i^2+H_i^2}\cdot |Q(e^i_j)|},
\end{split}
\end{equation}
where $Q_{e^i_j}$ refers to the quads that contains edge $e^i_j$;
$\Psi_i$ is the overlap region in Image $I_i$;
$Min(d_{cen(q_m, \Psi_i)})$ calculates the minimum distance between the center of quad $q_m$ to quads in $\Psi_i$;
$W$ and $H$ are the number of rows and columns in the mesh of image $I_i$.

With the energy terms defined above, we define the optimization for image stitching as
\begin{equation} \label{equ:global_stitching}
 \Phi_{stitch}(V)=\arg \min_{\hspace{-0.10in}\textbf{V}}(\gamma_a \phi_a(\textbf{V})+\gamma_s \phi_s(\textbf{V})+\gamma_g \phi_g(\textbf{V})).
\end{equation}

In Equ.~\ref{equ:global_stitching}, there are three weights $\gamma_a$, $\gamma_s$, $\gamma_g$, which controls the importance of the three terms. In our experiments, we set $\gamma_a=1.5$, $\gamma_s=10$, $\gamma_g=0.75$ for most of the cases. The stitching energy $\Phi(V)$ are quadratic and can be efficiently minimized by solving a sparse linear system.

\subsection{Irregular boundary extraction}
 \label{sec:irregular_boundary}
For panorama rectangling, we need to drag the vertices on the irregular boundary onto the regular boundary.
Different from~\cite{journals/tog/HeC013}, which place only one mesh. In our method, the irregular boundary consists of vertices from different image meshes, and there also exists some intersections in the overlapping regions, see the second row of Fig.~\ref{fig:pipline}(c).
Inspired by the boolean operations on polygons~\cite{journals/gandc/MartinezRF09}, We propose a simple and effective algorithm for irregular boundary construction.
See Alg.~\ref{alg:irregular_boundary}, the input is the mesh vertices $\mathbf{V}_i$ of each warped image $I_i$, and the goal is to get index of boundary vertices and the directions to be dragged.
We first get minimum outer rectangle $R$ of all warped meshes, and search $4$ corners of irregular boundaries according to the minimum distance between corners of each mesh $\mathbf{V}_i$ and $R$.
Then, we construct polygons $\vartheta$  using the contours of each mesh, and the irregular boundary $P$ can be efficiently calculated by the polygon boolean union operation of all boundary polygons.
With corners $\Delta$ and boundary polygon $P$, the boundary vertices of $4$ directions can be easily obtained by sequencially collecting vertices between neighboring corners of $P$.
As shown in Fig.~\ref{fig:polybool}, the initial image stitching result has irregular boundary which is the combination of $4$ meshes.
(b) shows contours of all meshes, and each contour has a different color.  the black circles are intersections of these contours.
As shown in (c), After the polygon boolean union operations, the irregular boundaries are correctly sorted. With the detection of four corners, boundary vertices (including intersections) are easily detected and classified into $4$ directions.
For the intersection points, which cannot be constrained as vertices. We first detect the corresponding intersected vertices $\kappa$, and calculate the interpolation weight of the vertices $\eta$,
then the intersection points can be easily constrained by the neighboring vertices.

%Fig.~\ref{fig:polybool2} shows a challenging example which contains a number of meshes and complex overlaps, and our method can robustly extract and sort the irregular boundary.

\begin{algorithm}
 \label{alg:irregular_boundary}
%    \SetAlgoNoLine
     \caption{Irregular boundary extraction}
      \KwIn{Mesh vertices $\mathbf{V}_i$ of each warped image $I_i$, $ i=1, 2,\ldots, N$}
      \KwOut{Index of boundary vertices $\Re$ and their labels $\zeta$}
        Get minimum outer rectangle $R$ of all meshes\;
        Set $D_{min} = Dist(Corners(R), Corners(\mathbf{V}_i))$\;
        construct polygon $\vartheta_1$ using contour vertices of mesh $\mathbf{V}_i$\;
        Set $P=\vartheta_1$\;
        Set boundary corners $\Delta= Corners(\mathbf{V}_1)$\;
        \For{$(i=2;j \le N;j++)$}
        {
            Construct polygon $\vartheta_i$ using contour vertices of $I_i$\;
            Polygon boolean Union: $P=P\cup\vartheta_i$\;
            \If {$(dist(Corners(R), Corners(\mathbf{V}_i)<D_{min}))$}
            {
                    $\Delta = Corners(\mathbf{V}_i)$\;
                    $D_{min}=Dist(Corners(R), Corners(\mathbf{V}_i)$\;
            }
        }
        \For{$(j=1;j \le size(P); j++)$}
        {
            \If{$(P[j] \in vertices )$}
             {
                 $\zeta[P[j]]=1$\;
             }
             \ElseIf {$(P[j] \in intersections)$}
             {
                 $\zeta[P[j]]=0$\;
                 $\kappa[P[j]]=[V_m,V_n,V_p,V_q]$\;
                 $\eta[P[j]]=[C_m,C_n,C_p,C_q]^T$\;
             }
        }
       Get boundary vertices between neighboring corners of $P$\;
         \For{$(k=1;k \le 4;k++)$}
         {
                 $\Re(k)=P(\Delta(k),\Delta((k+1)\%4))$\;
         }
\end{algorithm}

\begin{comment}
\begin{figure}[t] %% htbp
  \centering
  \includegraphics[width=0.45\textwidth]{polybool}

  \caption{Flowchart of irregular Pipeline of \emph{StereoPasting}. In the preprocessing step, we first select and triangulate the 2D foreground, then estimate the disparity map of the target scene. After that we edit the disparity map of the 2D foreground by painting strokes and blend it with the 3D background for depth-consistent composition. At last, the 2D foreground is warped and blended into the target image pair to get the composition results.} \label{fig:polybool}
\end{figure}

\begin{comment}
\begin{figure}[t] %% htbp
  \centering
  \includegraphics[width=0.45\textwidth]{polybool2}

  \caption{A challenging example of irregular boundary construction.} \label{fig:polybool2}
\end{figure}
\end{comment}

\subsection{Piecewise rectangular boundary constraint}
For panoramic scenes with missing content, He et al.'s~\cite{journals/tog/HeC013} warping-based rectangling cannot work well, as it may introduce unexpected distortions, see Fig.~\ref{fig:pipeline}(i).
Actually, panorama images with irregular boundary cannot simply be warped to be a rectangle, and the rectangling process should be content-preserving.
%%By content-preserving, we mean that the shape of target boundary should be designed as rectangular as possible, while avoiding the unwanted distortions.
In this paper, we propose to the piecewise rectangular boundary which makes the target boundary as rectangular as possible, while avoiding the unwanted distortions.
See Fig.~\ref{fig:pipeline}(h), with the piecewise rectangular boundary, the stitching result can be cropped easily, while preserving more content in a cropping window.

%In fact, the core of our optimization for content-preserving stitching is to determine the regular boundary constraints.
%Our main idea is to rectangling the irregular boundary as much as possible(AMAP), as shown in Fig.~\ref{fig:pipeline}(f), such that the final stitched panorama not only preserve the regular boundary, but avoiding the unwanted distortions. See Fig.~\ref{fig:pipeline}(h), with the piecewise rectangular boundary, the stitching result can be cropped easily, while preserving more content in a cropping window.

%See Fig.~\ref{fig:piecewise}, we take the irregular\emph{ top } boundary for example, which consists of boundary vertices of different image meshes and their interactions.
Alg.~\ref{alg:piecewise_analysis} gives details of piecewise regular boundary analysis.
The input is mesh vertices of irregular boundaries $V^i$, and the output is the segmented boundary $S^i$, $i=1,2,3,4$ refers to index of $4$ directions.
The irregular boundaries are comprised of boundary vertices from different image meshes, which are connected by their intersections.
We first segment the $V_i$ by intersections and corner vertices (with red boundary in Fig.~\ref{fig:pipeline}(e)) of each mesh.
Then we combine neighboring segments with the same direction, and incorporate segments with less than $3$ vertices into previous segment.
After sorting the irregular boundaries, we calculate the target boundary value of each segment by averaging their coordinates in corresponding direction.
See Fig.~\ref{fig:pipeline}(f), the top and bottom boundary contain $3$ segments, and the steps are designed to reduce distortions in global warping.

\begin{algorithm}
 \label{alg:piecewise_analysis}
%    \SetAlgoNoLine
     \caption{Piecewise regular boundary analysis}
      \KwIn{Mesh vertices $\mathbf{V}^i$ of irregular boundaries, $ i=1, 2, 3, 4$ refer to $4$ directions(T/R/B/L)}
      \KwOut{Segmented boundary $S^i$, includes vertices, directions, and their target boundary values}
      Sequentially push intersections and corner points into $\mathbf{F}$\;
      Segment irregular boundary $\mathbf{V}^i$ by $\mathbf{F}$\;
      Set $prevDir=i$\;
      \For{$(j=1; j < size(F); j++)$}
      {
           $S^i_j=\mathbf{V}^i(F[j], F[j+1])$\;
           $S^i_j.dir=direction(F[j], F[j+1])$\;
      }
      \For{$(j=1; j <= size(S^i); j++)$}
      {
         \If{$(S^i[j].dir == prevDir \&\&  j>1)$}
         {
              $S^i[j] -> S^i[j-1]$\;
         }
         \Else
         {
               \If{$(dist(S^i[j], S^i[j-1]) < \varepsilon)$}
               {
                     $S^i[j] -> S^i[j-1]$\;
               }
               \Else
               {
                    $prevDir = S^i[j].dir$\;
               }
          }
           \If{$(S^i[j].dir\%2)$}
           {
                $S^i[j].val = Avg(V^i(S^i[j]).y)$\;
           }
           \Else
           {
                $S^i[j].val = Avg(V^i(S^i[j]).x)$\;
           }
      }
\end{algorithm}

\subsection{Piecewise rectangular stitching}
We design a global optimization which combines image stitching and rectangling.
Our energy function contains feature alignment, shape preserving and global similarity constraints that used for stitching,
and regular boundary, straight line preserving constraints that rectangling irregular boundaries while avoiding unexpected distortions.
The energy terms for stitching have been defined in Section~\ref{sec:Initial image stitching}, and we further define energy terms for irregular boundary rectangling as follows.

\textbf{Regular boundary preserving}.
With the piecewise rectangular boundary constraint, we define the regular boundary preserving energy as
\begin{equation} \label{equ:piecewise_boundary}
\begin{split}
   &\phi_r(\mathbf{V})=\sum\limits_{i=1}^4\sum\limits_{S^i_j \in \Re(i)}\sum\limits_{V_k \in S^i_j}|| \Lambda(S^i_j)^i[\zeta[V_k] V_k+(1-\zeta[V_k])\\
   &(\kappa[V_k] \cdot \eta[V_k])]-S^i_j.val ||^2,
\end{split}
\end{equation}

%\textbf{Regular boundary preserving}.
%With the extracted and sorted irregular boundaries $\Re$ in Section~\ref{sec:irregular_boundary}, we construct energy function to drag the irregular boundary to the outer rectangle boundaries, and the energy function is defined as
%\begin{equation} \label{equ:regular_boundary}
%\begin{split}
 %  &\phi_r(\mathbf{V})=\sum\limits_{i=1}^4\sum\limits_{V_j \in \Re(i)}|| \Lambda_{01}^i[\zeta[V_j] V_j+(1-\zeta[V_j])\\
  % &(\kappa[V_j] \cdot \eta[V_j])]-\delta_i||^2
%\end{split}
%\end{equation}
where $\Re(i), i=1,2,3,4$ refer to the set of vertices in $top$, $right$, $bottom$ and $left$ directions;
$S^i_j$ represents all segments in direction $i$, and $S^i_j.val$ refers to the values of each target boundary segment;
$\zeta[V_k]$ determines the type of vertices: $1$ - vertices, $0$ - intersections;
%$\delta_i, i=1,2,3,4$ present top/right/bottom/left boundary values of target rectangle;
%$\zeta$ represents labels of each $V_i$, 1-vertices, 0-intersections;
$\Lambda(S^i_j)$ is the $2\times1$ matrix, and $\Lambda(S^i_j)=[0\quad 1] $ or $[1\quad 0]$, when $S^i_j$ is horizontal or vertical.
For intersection points, we find their neighboring vertices $\kappa$ that generate the intersections, and their corresponding interpolation weights $\eta$,
then constrains are imposed on these vertices.

\textbf{Straight line preserving}.
To avoid unexpected distortion after warping, we also need to preserve straight lines in panoramas.
We use the line preserving term from~\cite{journals/cgf/LinLCZ16}, and the line segments detectors are proposed in~\cite{journals/pami/GioiJMR10}.
Given the line segments, our energy term is defined as
\begin{equation} \label{equ:line_preserving}
\begin{split}
    \phi_l(\mathbf{V}) = \sum\limits_{i=1}^N\sum\limits_{l \in L_i}\sum\limits_{j=1}^{M-1}||&(1-\mu)V_{l, 0}^i \omega_{l, 0}^i + \mu V_{l, M}^i \omega_{l, M}^i\\
    &-V_{l, j}^i \omega_{l, j}^i||^2,
\end{split}
\end{equation}
where $M$ is the number of sub-segments for each line segment, and each sample point on the line segment is represented by the bilinear interpolation of the $4$ grid vertices. The two end points are represented as $V_{l, 0}^i \omega_{l, 0}^i$, $V_{l, M}^i \omega_{l, M}^i$, and the sample point between the end points is $V_{l, j}^i \omega_{l, j}^i$.
The linear combination of them can easily preserve the straight lines, and the weight $\mu=j/M$.

With the piecewise regular boundary and straight line preserving constraints,  the energy function for content-preserving image stitching with regular boundary can be defined as
\begin{equation} \label{equ:content_preserving_stitching}
\Phi(\textbf{V})=\Phi_{stitch}(\textbf{V})+\gamma_r \phi_r(\textbf{V})+\gamma_l \phi_l(\textbf{V}),
\end{equation}
where $\Phi_{stitch}$ is the stitching energy function defined in Section~\ref{sec:Initial image stitching}, $\gamma_r$ and $\gamma_l$ are weights to control the importance of energy terms. We set $\gamma_r=10^3$ to ensure the regularity of boundaries.
In our experiment, we find that the line preserving is more important than the local shape preserving, thus $\gamma_l$ is set to be $20$ to avoid too much distortions in straight lines.

\subsection{Optimization}
We first solve optimization for the initial image stitching, which is defined in Equ.~\ref{equ:global_stitching}.
However, Equ.~\ref{equ:global_stitching} only constrains shape and scale of each mesh, which is not enough for stitching.
Thus, we add another term $\phi_p(\mathbf{V})=W\cdot||\mathbf{V}_0^0||^2$ to fix the position of stitched panorama, where
$\mathbf{V}_0^0$ refers to the first vertex(left-top corner) of the first image, and $M$ is a very large weight ($M=10^4$) to make $\phi_p$ a hard constraint.
Noting that, each energy term is quadratic and variables are mesh vertices of each image, the energy function can be efficiently optimized by solving a linear system.
Since this stitching step is only used to get the target rectangle and irregular boundary, we do not need to render the stitching result by warping and blending.

After the irregular boundary extraction, we solve the optimization defined in Equ.~\ref{equ:content_preserving_stitching} which incorporates the regular boundary and straight line constraint into the stitching framework.
Compared with initial image stitching, we add another two energy terms, which are also quadratic, thus the optimization can also be efficiently minimized.

With the optimized vertices of each mesh, we further warp each image by texture mapping and remove the visible seam by multibanded blending~\cite{journals/tip/ZhuLWZMLH18}.
For efficiency, we can also simply apply the linear blending, which can works well in most cases.
Fig.~\ref{fig:pipeline}(i) is stitching results constrained by piecewise rectangular boundary. Compared with previous rectangling~\cite{journals/tog/HeC013}, it makes a better balance between distortion and rectangling.

In this paper, we aim to rectangling the panorama with irregular boundary as much as possible, which means the final shape of the panorama should be as close as possible to a rectangle.
Thus, we try to further reduce steps on the piecewise rectangular boundary.
We propose a iterative solution which is described in Alg.~\ref{alg:piecewise_rectangling}.
The first iteration has been accomplished by the optimization above, see Fig.~\ref{fig:piecewise-process}(f),  and we calculate the energy values $E_0$ using the optimized vertices.
Then we iteratively find the optimal solution, that can preserve regular boundary as much as possible while avoid unwanted distortion.
%For each boundary with steps, we iteratively find the cut (see Fig.~\ref{fig:piecewise-opti}(d)), and connect the two segments connected by the cut, then
In the following iteration, for each step, we first analyze feature points and lines detection results near the boundary segments connected by the step, and when there are some features and lines, the step cannot be removed, see Fig.~\ref{fig:pipeline}(h), we preserve the two steps because of the features distributed in the roof and ground.
When feature and lines are not salient, such as grass and sky, we further analyze it as follows: for each step, we connect the segments neighboring to it, and reconstruct the  $S^i$, then perform image stitching again, finally we choose to remove the step with the minimum energy value $E$.
In each iteration, the threshold $\sigma=|E_t-E_0|/20$, according to many experiments.
When the energy value $E_t-E_0 > \sigma$, it means that the distortion in this iteration is not acceptable. Thus the iteration stops, and we finally get the optimal solution for the piecewise rectangling.
Actually, the panorama rectangling proposed by He et al.~\cite{journals/tog/HeC013} can be classified as a special case of our piecewise rectangling, when there is no steps in the target boundaries.
Fig.~\ref{fig:piecewise-process} (e) is the rectangling result by our method when all steps are removed, and there exists too much distortions in the bottom-right side.
Compared with He et al.'s~\cite{journals/tog/HeC013} result in Fig.~\ref{fig:piecewise-process} (d) which contains holes and distortions, our rectangling result is better.
Fig.~\ref{fig:piecewise-process}(f~i) are results of piecewise rectangling in each iteration, and the top-right corner shows the shape of target regular boundary.
Results show that each iteration can make the boundary of panorama be closer to a rectangle, and finally we get panorama with optimal piecewise rectangular boundary and unnoticeable distortions.

\begin{figure*}
  \centering
  \includegraphics[width=0.9\textwidth]{piecewise-opti}
  \caption{Piecewise rectangling in image stitching. (a) Initial stitching result with irregular boundary. (b) Irregular boundary extraction. (c) Target boundaries estimation.
  (d) He et al.'s~\cite{journals/tog/HeC013} rectangular stitching result. (e) Our rectangular stitching result. (f~i) stitching results by iterative piecewise rectangling, and (i) is our final stitching result. } \label{fig:piecewise-process}
\end{figure*}


\begin{algorithm}
 \label{alg:piecewise_rectangling}
%    \SetAlgoNoLine
     \caption{Iterative piecewise rectangling stitching}
      \KwIn{Source images,   $\textbf{S}$ refers to segments of the piecewise rectangular boundary in $4$ directions, and $\textbf{P}$ represents steps that connect all segments}
      \KwOut{Stitching result with optimized regular boundary}
      Stitching with $\textbf{S}$ as boundary constraints\;
      $E_0 = \Phi(\textbf{V}), \textbf{V}$ is the optimized vertices\;
      \While{(1)}
      {
           $Idx=0, E_t=10^6$\;

           \For{$(k=0;k<size(\textbf{P});k++)$}
           {
                  segments connected by $\textbf{P}[k]$\;
                  reconstruct $\textbf{S}$\;
                  Stitching with $\textbf{S}$ as boundary constraints\;
                  $E = \Phi(\textbf{V})$\;
                  \If{$(E<E_t)$}
                  {
                       $Idx=k$\;
                        $E_t = \Phi(\textbf{V})$\;
                  }
           }
           \If{($(E_t-E_0)<\sigma)$}
           {
                remove $\textbf{P}[Idx]$\;
                $E_0=E_t$\;
           }
           \Else
           {
                break;
           }
           \If{$size(\textbf{P})==0$}
           {
               break;
           }
      }
\end{algorithm}

\begin{comment}
\subsection{Piecewise rectangling}
Similar to He's~\cite{journals/tog/HeC013} rectangling, the proposed approach above can not works well when there are missing content.
As shown in Fig.~\ref{fig:piecewise-process}, in challenging cases, e.g. scenes with missing contents, Our rectangular stitching result can preserve regular boundaries, but the image content is  distorted, see Fig.~\ref{fig:piecewise-process}(e).
 Fig.~\ref{fig:piecewise-process}(d) is the rectangling panorama by He's method~\cite{journals/tog/HeC013}. We find that their result contains big hole in the top boundary, and the distortion is more severe.
In fact, such panorama cannot simply warped to be a rectangle, we need to rectangling it in a content-aware manner.
In this paper, we propose a piecewise rectangling approach, which not only boundary regularity and but avoid unexpected distortion.
Our main idea is to straighten the irregular boundary as much as possible, as shown in Fig.~\ref{fig:piecewise-process}(f~i), we straighten the irregular boundaries iteratively in a  piecewise manner, and the final panorama can preserve straight boundary as much as possible, without breaking the distortion limits. We give details of the algorithm as follows.

%See Fig.~\ref{fig:piecewise}, we take the irregular\emph{ top } boundary for example, which consists of boundary vertices of different image meshes and their interactions.
Algorithm~\ref{alg:piecewise_analysis} gives details of piecewise regularity analysis.
The input is mesh vertices of irregular boundaries $V^i$, and the output is the segmented boundary $S^i$, $i=1,2,3,4$ refers to index of $4$ directions.
The irregular boundaries are comprised of boundary vertices from different image meshes, which are connected by their intersections.
We first segment the $V_i$ by intersections and corner points(marks black boundary in Fig.~\ref{fig:piecewise-process}(c)).
Then we combine neighboring segments with the same direction, and incorporate segments with less than $3$ vertices into previous segment.
After sorting the irregular boundaries, we calculate the target boundary value of each segment by averaging their coordinates in corresponding direction, see Fig.~\ref{fig:piecewise-process}(d).

\begin{algorithm}
 \label{alg:piecewise_analysis}
%    \SetAlgoNoLine
     \caption{Piecewise regularity analysis}
      \KwIn{Mesh vertices $\mathbf{V}^i$ of irregular boundaries, $ i=1, 2, 3, 4$ refer to $4$ directions(T/R/B/L)}
      \KwOut{Segmented boundary $S^i$, includes vertices, directions, and their target boundary values}
      Sequentially push intersections and corner points into $\mathbf{F}$\;
      Segment irregular boundary $\mathbf{V}^i$ by $\mathbf{F}$\;
      Set $prevDir=i$\;
      \For{$(j=1; j < size(F); j++)$}
      {
           $S^i_j=\mathbf{V}^i(F[j], F[j+1])$\;
           $S^i_j.dir=direction(F[j], F[j+1])$\;
      }
      \For{$(j=1; j <= size(S^i); j++)$}
      {
         \If{$(S^i_j.dir == prevDir \&\&  j>1)$}
         {
              $S^i_j -> S^i_{j-1}$\;
         }
         \Else
         {
               \If{$(dist(S^i[j], S^i_{j-1}) < \varepsilon)$}
               {
                     $S^i[j] -> S^i_{j-1}$\;
               }
               \Else
               {
                    $prevDir = S^i_j.dir$\;
               }
          }
           \If{$(S^i[j].dir\%2)$}
           {
                $S^i[j].val = Avg(V^i(S^i_j).y)$\;
           }
           \Else
           {
                $S^i[j].val = Avg(V^i(S^i_j).x)$\;
           }
      }
\end{algorithm}


\begin{algorithm}
 \label{alg:piecewise_rectangling}
%    \SetAlgoNoLine
     \caption{Iterative piecewise rectangling stitching}
      \KwIn{Source images, Segmented boundary $S^i, i=1, 2, 3, 4$ refer to $4$ directions(T/R/B/L)}
      \KwOut{Stitching result with optimized regular boundary $S^i$}
      Stitching with $S_i$ as boundary constraints\;
      $E_0 = \Phi(\textbf{V}), \textbf{V} is optimized vertices$\;
      \While{(1)}
      {
           $mIndex=1, E_t=10^6$\;
           \For{$(k=1;k<size(cut);k++)$}
           {
                  connect segments in the neighboring of $cut[k]$\;
                  reconstruct $S_i$\;
                  Stitching with $S_i$ as boundary constraints\;
                  $E = \Phi(\textbf{V})$\;
                  \If{$(E<E_t)$}
                  {
                       $mIndex=k$\;
                        $E_t = \Phi(\textbf{V})$\;
                  }
           }
           \If{($(E_t-E_0)<\sigma)$}
           {
                remove $cut[mIndex]$\;
                $E_0=E_t$\;
           }
           \Else
           {
                break;
           }
           \If{$size(cut)==0$}
           {
               break;
           }
      }
\end{algorithm}

Based on the piecewise rectangular boundary, we further optimize our image stitching by iterative optimization, as shown in Algorithm~\ref{alg:piecewise_rectangling}.
We first redefine the energy term $\phi_r$  in Equ.~\ref{equ:content_preserving_stitching} using the piecewise rectangular boundary constraint as
\begin{equation} \label{equ:piecewise_boundary}
\begin{split}
   &\widetilde{\phi_r}(\mathbf{V})=\sum\limits_{i=1}^4\sum\limits_{S^i_j \in \Re(i)}\sum\limits_{V_k \in S^i_j}|| \Lambda_{01}^i[\zeta[V_k] V_k+(1-\zeta[V_k])\\
   &(\kappa[V_k] \cdot \eta[V_k])]-S^i_j.val ||^2
\end{split}
\end{equation}

Then the energy function for rectangling stitching is redefined as
\begin{equation} \label{equ:piecewise_stitching}
\widetilde{\Phi}(\textbf{V})=\Phi_{stitch}(\textbf{V})+\gamma_r \widetilde{\phi_r}(\textbf{V})+\gamma_l \phi_l(\textbf{V}),
\end{equation}

\end{comment}

 \section{RESULTS AND APPLICATIONS}

In this section, we show a variety of panoramic images by image stitching with regular boundary constraint, and applications that benefit from our approach.
Then we further give performance and limitation of our method.
In this paper, we use the dataset provided by Chen et al.~\cite{conf/eccv/ChenC16} for image stitching, and the data for video stitching is from Perazzi et al.'s paper~\cite{journals/cgf/PerazziSZKWWG15}. For better exposition, we only provide input for examples provided by ourselves.

 \subsection{Results}

Fig.~\ref{fig:holes_he} is the comparison of our method with He et al.'s method~\cite{journals/tog/HeC013}. The left initial stitching is the first step of our method. For fair comparison, we also take it as the input of He et al.'s method. As shown in the comparison, the main difference between the two method is the number of mesh used in the global warping.
Actually, it is hard to place mesh on images with irregular boundary, and the boundary of the mesh always contain some holes(see bottom side of (a) and (b)), which will finally degrade the quality of the final rectangular panorama, see the zoom-in view in (c). In addition, He et al's method treat stitching and rectangling as two individual processes, thus cannot well preserve the local and global structure of the panorama. In our method, the meshes are placed on the each rectangular images, and the warping are guided by the global optimization which combines stitching and rectangling constraints, thus can produce stitching with regular boundaries while reducing the local and global distortion.

 \begin{figure*} %% htbp
  \centering
  \includegraphics[width=0.9\textwidth]{holes_He}
  \caption{Comparison with He et al.'s method~\cite{journals/tog/HeC013}. The initial stitching is the first step of our method, which is also the input of He et al.'s method~\cite{journals/tog/HeC013}. For He et al.'s method: (a) mesh of on the input image; (b) mesh after global warping; (c) final rectangular panorama.
  For our method: (d) meshes of our initial stitching; (e) meshes after the global warping; (f) our rectangular panorama.} \label{fig:holes_he}
\end{figure*}

Fig~\ref{fig:result_office} gives comparison with state-of-the-art methods in terms of line preserving. In Chen et al.'s method~\cite{conf/eccv/ChenC16}, their line segment detection is used for global feature preserving, like scale and rotation, but they cannot preserve straight lines, as shown in (a). He et al.'s method is limited to the input, and when the input panorama fails to preserve straight lines, their method also fails, see the arrows in (b). (c) and (d) are the initial piecewise rectangular stitching results with and without line preserving, and results show that our method can well preserve straight line in our optimization framework. (e) is the final result after several iterations, which not only preserves lines, but avoid unexpected distortions.

 \begin{figure*} %% htbp
  \centering
  \includegraphics[width=1.0\textwidth]{result1}
  \caption{Comparison with state-of-the-art methods. (a) Chen's~\cite{conf/eccv/ChenC16} stitching with global prior. (b) He et al.'s~\cite{journals/tog/HeC013} rectangling stitching. (c) and (d) are Our piecewise rectangling results in the $1_{st}$ iteration with and without line preserving). (e) our final stitching results after several iterations. } \label{fig:result_office}
\end{figure*}

Fig.~\ref{fig:piecewise-compare} gives results and comparison of stitching with missing contents in the scene. We provide two groups of experiments to show the effectiveness of our method in challenging cases. (a) is the initial stitching results, which is also the input of He et al.'s~\cite{journals/tog/HeC013} method. (b) and (c) show the meshes after initial stitching and the extracted irregular boundaries.
(d) and (e) are the rectangular stitching results by He et al.'s and our method. Although both of them has severe distortions, our result is more reasonable and visual pleasing. In addition, the result by He et al.'s method has holes, due to the drawbacks of their mesh. (f) is our piecewise rectangling result, which is the optimal panorama with less distortion, and can preserve the content of panorama in the rectangular windows as much as possible.

\begin{figure*}
  \centering
  \includegraphics[width=0.9\textwidth]{compare}
  \caption{Results and comparison of stitching with missing contents. There are two sets of results, and each set is as follows: (a) Initial stitching result with irregular boundaries. (b)  Warped meshes of initial stitching. (c) Irregular boundary extraction. (d) and (e) are rectangling stitching by He's~\cite{journals/tog/HeC013} and our method respectively. (f) our piecewise rectangular stitching result.} \label{fig:piecewise-compare}
\end{figure*}

Fig.~\ref{fig:completion} shows comparison with image completion. (a) is the initial stitching result. By completing holes in (a) using Huang et al.'s~\cite{journals/tog/HuangKAK14} method, we get rectangular panorama as shown in (c). Zoom-in view in (c) shows that the completion method is limited to synthesize semantic contents. (b) is the piecewise rectangling method, and our method tries the best to preserve regular boundaries while preventing unwanted distortions. Based on our result, image completion can be used to synthesize the regular hole on the left, result in (d) shows that the combination of our method and completion is successful.

 \begin{figure} %% htbp
  \centering
  \includegraphics[width=0.5\textwidth]{completion}
  \caption{Comparison with image completion. (a) is the result of initial stitching. (b) shows our piecewise rectangling panorama.(c) is the result by Huang et al.'s~\cite{journals/tog/HuangKAK14} image completion. (d) our final result which is generated by completing holes in (b). } \label{fig:completion}
\end{figure}

\begin{comment}
 \begin{figure} %% htbp [t]
  \centering
  \includegraphics[width=0.45\textwidth]{crop}
  \caption{Content-ware cropping. (a) Chen et al.'s~\cite{conf/eccv/ChenC16} stitching with global prior. (b) He et al.'s~\cite{journals/tog/HeC013} rectangular stitching result.
  (c) Our piecewise rectangular stitching result.} \label{fig:crop}
\end{figure}
\end{comment}

Fig.~\ref{fig:challenging_cases} gives results of challenging cases, and each case is very different from common examples. The first row is results of initial stitching result with irregular boundaries, and the second row shows our piecewise rectangling panorama. With the piecewise rectangular boundaries, the panorama can be easily cropped and completed, thus can improve the visual effects and user experience of panorama.

 \begin{figure} %% htbp [t]
  \centering
  \includegraphics[width=0.5\textwidth]{challenging}
  \caption{Results of challenging cases. The $1^{st}$ row shows Initial stitching results with irregular boundaries, and the $2^{nd}$ row shows results of our piecewise rectangling stitching.} \label{fig:challenging_cases}
\end{figure}

 \begin{figure*} %% htbp
  \centering
  \includegraphics[width=0.88\textwidth]{results}
  \caption{More results of our method. The initial stitching is traditional method without the regular boundary constraint, and final results are obtained by our rectangular stitching.} \label{fig:more_results}
\end{figure*}

 \subsection{Applications}

 \subsubsection{Selfie expansion}

Recent years, with the fast development of intelligent devices such as smart phones, pad etc., selfies have become more and more popular.
In general, selfie images are mostly shot by mobile phones by holding them or fixing them to selfie sticks.
Since the camera is very close to people, the selfie photos are always limited by the field-of-view, thus reducing the fun of selfies.
To produce selfies with large field-of-view, we apply our image stitching to producing selfie panorama.
Actually, the front-facing camera which is used for selfie shotting, can not shoot a panorama view.
We first take photos of the panorama view using the back camera, then shot our portrait using the front-facing camera on the background of the panorama.
See Fig.~\ref{fig:selfie}, (a) is the input, which contains photos for the panorama background, and the portrait photo.
(b) is the result by Chen et al.'s stitching~\cite{conf/eccv/ChenC16}, which contains irregular boundaries.
(c) is result by our method. However, the portrait is distorted too much.
We first detect the face the portrait photo, and modify Equ.~\ref{equ:shape_preserving} as
\begin{equation} \label{equ:shape_preserving1}
\begin{split}
    \phi_s(\mathbf{V}) = \sum\limits_{i=1}^N\sum\limits_{j} \
    \alpha_j^i||V_j^i -V_1^i-\xi \mathbf{R}(V_0^i -V_1^i)||^2,
\end{split}
\end{equation}
where $alpha_j^i$ refers to the saliency value of vertex $V_j^i $, we give a big value ($alpha_j^i$=20) for vertices in the face region, and $1$ for others.
By preserving the shape of  mesh in the face region, the stitching result is much more visual pleasing, as shown in (d).

 \begin{figure} %% htbp
  \centering
  \includegraphics[width=0.48\textwidth]{selfie}
  \caption{Application of \emph{Selfie} panorama. (a) Initial stitching results with irregular boundaries. (b) Results of our stitching with regular boundary, which distorts the human face. (c) Results of our stitching with regular boundary and face detection, which can avoid the unwanted face distortion. } \label{fig:selfie}
\end{figure}


\subsubsection{Rectangling Video Panorama}

We further apply our method to videos.
Actually, it is difficult to stitch the videos from independent hand-held cameras, and rectangling them is even more challenging.
Because the regular boundary in each frame is different and the temporal coherence is difficult to maintain due the the shaking in each video.
Inspired by Perazzi et al.'s~\cite{journals/cgf/PerazziSZKWWG15} work, we aim to rectangling panorama videos from unstructured camera arrays, which are fixed on a rag.
For fixed camera configurations,  the warping parameters for stitching in each frame are nearly invariant.
For temporal coherence, we propose a simple and effective scheme as follows.
We first divide videos into several blocks ($1$ block=$30$ frames), and neighboring block has $10$ frames overlap.
For each block, we compute the stitching result for the first frame, and the warping parameters are used for other frames.
For the overlapping part, the warping parameters are linear combination of neighboring blocks.
Fig.~\ref{fig:video} shows result two sets of results, and each set shows video panoramas of different frames by Perazzi et al.'s~\cite{journals/cgf/PerazziSZKWWG15} and our method.
Comparison shows that our method is effective to rectangling video panorama shot by fixed camera arrays.

 \begin{figure*} %% htbp
  \centering
  \includegraphics[width=0.9\textwidth]{video}
  \caption{Application of rectangling video panorama. We give two examples, and each example shows stitching results of $4$ different frames using Perazzi et al.'s~\cite{journals/cgf/PerazziSZKWWG15} method and our rectangling respectively.} \label{fig:video}
\end{figure*}

 \subsection{Performance}
We report performance of our method on a Intel Core i7 8550U 1.99GHz laptop with 16G RAM for examples in this paper. Take Fig.\ref{fig:pipeline} for example, the input contains $5$ images, and size of each image is $800\times600$, the initial stitching cost $0.76$s, which includes feature matching, energy construction and optimization.
Then, the stitching with rectangular boundary constraint cost $0.49$s, which include the irregular boundary extraction, boundary constraint construction and iterative optimization. Finally, with the warped vertices, texture mapping and blending are performed, and the time cost is $2.15$s.
In our two-step optimization, the energy terms are similar, thus we construct them only once. In addition, the energy terms are quadratic, thus can be efficiently solved.
For our iterative optimization in the piecewise rectangling, results in each iteration are similar, thus we apply conjugate gradient method, which takes result of last iteration as input, thus can solve the optimization more efficiently.

  \subsection{Limitations}
Due to the free movement of hand-held cameras, panorama images has irregular boundaries and missing contents.
Our piecewise rectangling stitching can effectively rectify these problems by warping-based optimizations with regular boundary constraints.
However, there are still some limitations:
(1) Similar to most warping-based methods, our method cannot well preserve all lines when there are many lines in local regions.
(2) Our method may fail when there is strong structure near the intersection of neighboring meshes. See Fig.~\ref{fig:failure}, the zoom-in view show that, our piecewise rectangling scheme may introduce unwanted distortion in order to preserve the rectangular boundaries.

 \begin{figure} %% htbp
  \centering
  \includegraphics[width=0.5\textwidth]{failure}
  \caption{Failure case: when there is strong structure in the intersection of meshes, our method may fail to preserve the structure.} \label{fig:failure}
\end{figure}

 \section{CONCLUSION}
In this paper, we have proposed an efficient approach for content-preserving stitching with the regular boundary constraint, thus can generate panorama images with regular boundaries.
Our main contribution is to propose a global optimization which incorporates the regular boundary constraint in the framework of image stitching.
Based on the traditional stitching with irregular boundaries, we analyze the warped meshes and extract the outer boundary by the polygon boolean operation.
With the outer boundary, we setup the piecewise rectangular boundary constraint for the content-preserving stitching.
Compare with He et al.'s panorama rectangling, our method is more robust and effective.
Especially for panoramic scenes with missing content, our piecewise rectangling can not only regularize the stitching boundary as-much-as-possible, but avoids unwanted distortions.
Experimental results and comparisons show that our method is effective and better than state-of-the-art methods. Some challenging examples show the robustness and practicability.
We further apply our method to Selfie panorama and video stitching, which demonstrate the versatility of our approach.

In the future, we will consider more features to improve the performance of panorama boundary rectangling, such as structure, saliency, scene analysis etc.
For video stabilization and stitching, the warping-based method may also introduce the irregular boundaries.
Regularizing the boundary of warped videos can preserve more content in a cropping window and improve the viewing experiences.
However, for videos shot by freely moving hand-held cameras, it is difficult to define the regular boundary constraint, and maintain the spatial-temporal coherence.
We leave these problems as our future work.



 %\begin{equation} \label{equ:brush_diffusion}
%\begin{aligned}
 %   E(u)=&\sum\limits_{p\in I} (w_{d}(p)(u(p)-d(p))^{2}+\\
  %  &\nabla \textbf{u}_{p}^{T} \textbf{w}_{p}\nabla\textbf{u}_{p})
%\end{aligned}
%\end{equation}

%where $d(p)$ refers to the values on the strokes, and $w_d(p)$ specifies the mask of the strokes.
%$\nabla \textbf{u}$ denotes the gradient of the disparity map $u$ along the x and y axis. $\textbf{w}_{p}$ refers to a 2x2 diagonal matrix whose diagonal elements are $w_{x}(p)$ and $w_{y}(p)$.

%\begin{equation}
%w_d(p)=\left\{
 %            \begin{array}{ll}
  %                  \infty & p \in strokes \\
   %                 0  & otherwise
   %          \end{array}
   %     \right.
%\end{equation}

% \begin{figure*}[t] %% htbp
 % \centering
 % \includegraphics[width=1.0\textwidth]{Figure1}

  %\caption{Pipeline of \emph{StereoPasting}. In the preprocessing step, we first select and triangulate the 2D foreground, then estimate the disparity map of the target scene. After that we edit the disparity map of the 2D foreground by painting strokes and blend it with the 3D background for depth-consistent composition. At last, the 2D foreground is warped and blended into the target image pair to get the composition results.} \label{fig:pipeline}
%\end{figure*}



% The very first letter is a 2 line initial drop letter followed
% by the rest of the first word in caps (small caps for compsoc).
%
% form to use if the first word consists of a single letter:
% \IEEEPARstart{A}{demo} file is ....
%
% form to use if you need the single drop letter followed by
% normal text (unknown if ever used by the IEEE):
% \IEEEPARstart{A}{}demo file is ....
%
% Some journals put the first two words in caps:
% \IEEEPARstart{T}{his demo} file is ....
%
% Here we have the typical use of a "T" for an initial drop letter
% and "HIS" in caps to complete the first word.



%\hfill mds
%\hfill August 26, 2015




% if have a single appendix:
%\appendix[Proof of the Zonklar Equations]
% or
%\appendix  % for no appendix heading
% do not use \section anymore after \appendix, only \section*
% is possibly needed

% use appendices with more than one appendix
% then use \section to start each appendix
% you must declare a \section before using any
% \subsection or using \label (\appendices by itself
% starts a section numbered zero.)
%


% use section* for acknowledgment
\ifCLASSOPTIONcompsoc
  % The Computer Society usually uses the plural form
  \section*{Acknowledgments}
The authors would like to thank...


% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi



% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://mirror.ctan.org/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
\bibliographystyle{IEEEtran}
\bibliography{tvcg}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)

%\begin{thebibliography}{1}

%\bibitem{IEEEhowto:kopka}
%H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
 % 0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.

%\end{thebibliography}

% biography section
%
% If you have an EPS/PDF photo (graphicx package needed) extra braces are
% needed around the contents of the optional argument to biography to prevent
% the LaTeX parser from getting confused when it sees the complicated
% \includegraphics command within an optional argument. (You could create
% your own custom macro containing the \includegraphics command to make things
% simpler here.)
%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{mshell}}]{Michael Shell}
% or if you just want to reserve a space for a photo:

%\begin{IEEEbiography}{Michael Shell}
%Biography text here.
%\end{IEEEbiography}

% if you will not have a photo at all:
%\begin{IEEEbiographynophoto}{John Doe}
%Biography text here.
%\end{IEEEbiographynophoto}

% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}



% that's all folks
\end{document}


=======

\documentclass[10pt,journal,compsoc]{IEEEtran}



% *** CITATION PACKAGES ***
%
\ifCLASSOPTIONcompsoc
  % IEEE Computer Society needs nocompress option
  % requires cite.sty v4.0 or later (November 2003)
  \usepackage[nocompress]{cite}
\else
  % normal IEEE
  \usepackage{cite}
\fi


% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
   \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
   \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi



\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{algorithmic}
\usepackage{array}

% *** SUBFIGURE PACKAGES ***
\ifCLASSOPTIONcompsoc
  \usepackage[caption=false,font=footnotesize,labelfont=sf,textfont=sf]{subfig}
\else
  \usepackage[caption=false,font=footnotesize]{subfig}
\fi


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

\graphicspath{{images/}}

\begin{document}

\title{Content-Preserving Image Stitching with the Regular Boundary Constraint} % title must contain stitching


\author{Yun Zhang,
        Yu-Kun Lai,~\IEEEmembership{Member,~IEEE,}
        and~Fang-Lue Zhang,~\IEEEmembership{Member,~IEEE}% <-this % stops a space
\IEEEcompsocitemizethanks{\IEEEcompsocthanksitem Yun Zhang is with the Institute of Zhejiang Radio and TV Technology, Communication University of Zhejiang, Hangzhou, China, 310018.\protect\\
E-mail: zhangyun@cuz.edu.cn
\IEEEcompsocthanksitem  Yu-Kun Lai is with the School of Computer Science and Informatics, Cardiff University, Wales, UK,  CF24 3AA.\protect\\
E-mail: Yukun.Lai@cs.cardiff.ac.uk
\IEEEcompsocthanksitem Fang-Lue Zhang is with the School of Engineering and Computer Science, Victoria University of Wellington, New Zealand.\protect\\
E-mail: fanglue.zhang@ecs.vuw.ac.nz
}% <-this % stops an unwanted space
\thanks{}}

% The paper headers
\markboth{}%
{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for Computer Society Journals}


\IEEEtitleabstractindextext{%
\begin{abstract}

This paper proposes content-preserving stitching with the regular boundary constraint, which aims to preserve as much as possible content in image stitching, and avoid losing too much information in the irregular boundary cropping, so that the shape stitched images can be normalized to be the regular.
In our method, the traditional stitching is improved by considering the regular boundary constraint, and the stitching process is configured to be a two-step global optimization which can be efficiently solved.
With a grid mesh on each images for stitching, we first conduct stitching by traditional warping-based optimization, and get the outer rectangle of stitching results.
Then, we obtain the boundary vertices on the irregular warped meshes by the polygon boolean operations.
With the boundary vertices, we proceed the second step optimization to preserve the feature alignment, local shape, and global features.
To reduce the distortion after rectangling, we optimize the rectangling strategy in a content-aware manner.
We further extend the idea of content-preserving to videos and Sefie photography, and integrate the temporal coherence and portrait-preserving into the optimization.
Experiments show that our method can efficiently produce visual-pleasing results with unnoticeable distortion and artifacts.
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
AMAP-stitching, rectangling, warping, content-aware.
\end{IEEEkeywords}}


% make the title area
\maketitle


\IEEEdisplaynontitleabstractindextext

\IEEEpeerreviewmaketitle


\IEEEraisesectionheading{\section{INTRODUCTION}\label{sec:introduction}}
\IEEEPARstart{T}{he} rapid recent advances in digital visual media mean that the public now capture and produce high-quality images and videos, which has promoted the computer graphics applications that utilise visual data captured by ordinary users. Panoramic images/videos are one of these successful applications. With the integrated panorama module in their smart phones and portable cameras, people can easily take a panorama photo simply by moving cameras. It is also the most feasible way to get virtual reality content for immersive vision experiences. However, not like the well calibrated images captured by professional devices with a camera array, the intrinsic and extrinsic parameters of the images captured by consumer-level devices are difficult to estimate. Thus, a robust image stitching method which directly stitches using the visual content is much more important for the applications designed for the ordinary users,

Recently there has been good progress in image stitching. However, due to the casual motion of the hand-held cameras, after feature alignment, most stitching results from previous methods have irregular boundaries. When we want to display the full panorama in common screens, or generate free-viewpoint photos from one part of the whole scene recorded by the image collection, we can only show them in rectangular windows. The most simple method is cropping. but it will lose important content of stitched panorama, thus may reduce the impression of wide angle photography. In order to produce panorama images with rectangular boundaries, image completion techniques~\cite{journals/mta/YenYC17,journals/tog/BarnesSFG09} are used to synthesise the missing region in the panorama's bounding box. However, these methods are not stable, and may fail when there need to be semantic meaningful objects. He et al.~\cite{journals/tog/HeC013} proposed a warping based method to rectangling panorama images, which can stably produce visual-pleasing panorama images with rectangular boundaries. But their method suffers from the following problems: (1) The stitching and rectangling are two separated processes, so the latter rectangling step may twist the optimized stitching result, making it hard to get an optimal rectangle panorama. (2) When placing grid meshes in stitched irregular panoramas for rectangling, boundary meshes may contain small holes; (3) The warping-based method will produce large distortion and destroy the feature alignment, when the scene is not completely shot.Thus, when the gap between the rectangle boundary and irregular panorama boundary is large, or there are holes which are hard for completion and warping methods to fill, there need to be a better approach to create the panorama with regular boundaries.

%\IEEEPARstart{I}{mage} stitching is a well-studied problem, which has been successfully applied to smart phones and portable cameras, and people can easily take panorama images simply by moving cameras.
%Panorama images are popular due to the wide viewing and immersion experiences, and rise of VR further expands the application of stitching techniques.
%Due to the casual moving of hand-held cameras, after feature alignment, most stitching results have irregular boundaries. For better viewing, the final results generated by our cameras are usually cropped by rectangular windows.
%Although simple and effective, the cropping-based method can not preserve complete content of stitched panorama, thus may reduce the impression of wide angle photography.
%In order to produce panorama images with regular boundaries, image completion techniques~\cite{journals/mta/YenYC17,journals/tog/BarnesSFG09} are used to synthesize the missing region in the bounding box. However, these methods are not stable, and may fail to synthesize semantic contents in images.

%To generate panorama images with irregular boundaries, He et al.~\cite{journals/tog/HeC013} proposed a warping based method to rectangling panorama images, which can stably produce visual-pleasing panorama images with rectangular boundaries.
%Although useful and effective, their method treats stitching and rectangling as two individual processes, thus still suffer from some problems: (1) The rectangling and stitching may affect each other, thus it is hard to get optimized results; (2) It is hard to place grid meshes in irregular input panoramas, and boundary meshes may contain small holes; (3) The warping-based method will produce large distortion and destroy the feature alignment, when the scene is not completely shot.
%Actually, the warping-based rectangling~\cite{journals/tog/HeC013} are effective only when the gap between the rectangle and the irregular boundary is small, and the content is enough to make a rectangle panorama with unnoticeable distortion, which limits the range of application.
I%n practice, users tend to shot images with hand-held cameras in a casual manner, and direct retangling irregular boundaries may introduce too much distortions, which degrades the visual effects of panorama.
In this paper, we propose a content-preserving image stitching method, which aims to regularise the boundary of stitched panorama, and preserve as much as possible content after rectangular cropping. Our method is based on the following observations:
(1) Rectangling and stitching are tightly related, and combination of the two processes will generate the optimal rectangling panorama in a content-aware manner.
(2) The applications of panorama rectangling require the method to preserve as much as possible image content in a cropping window without annoying distortion, i.e., free-viewpoint photo generation, Thus it is not necessary to warp the boundary to a single rectangle; a piece-wise rectangle will be more appropriate. Thus, the key idea of our algorithm is a mesh-based global optimization approach which can jointly optimize the boundary and content stitching to get a piecewise rectangular panorama.   
%two-step optimization, that first stitch images using state-of-the-art method to get irregular boundaries, and then globally optimize the mesh to get stitching results with regular boundaries.
Our method firstly needs an initial stitched result, where we use image stitching with the global similarity prior~\cite{conf/eccv/ChenC16}, and get the boundary vertices by the polygon boolean union operation.
%In the first step, we apply image stitching with the global similarity prior~\cite{conf/eccv/ChenC16}, and get the boundary vertices by the polygon boolean union operation.
In our global optimization, we first organize the boundary vertices, and combine meshes according to the intersections on the boundary. Inspired by state-of-the-art stitching~\cite{conf/eccv/ChenC16}, we take the regular boundary, shapes preserving, straight lines, and global similarity constraints into account when optimizing the final grid vertices. We first get the result by simply rectangling the panorama, Then we iteratively optimize the boundary constraints in a piece-wise manner for optimal results with less distortion and better visual effects.
Our method works well in a variety of cases, and can produce visual-pleasing results with no user interactions.
For challenging cases, such as large missing regions for a whole panorama rectangle, we piece-wisely regularize the boundary, which can help users easily crop panorama while preserving as much as possible content in the cropping window.
In addition, our method can be applied in videos and selfie photography, and can produce panorama video and selfie with regular boundary.

Contributions of this paper are as follows:
\begin{itemize}
   \item We propose a global optimization to rectangling the irregular boundary problem in the stitching framework by considering the regular boundary constraint, and our method can be easily applied to panorama selfie and videos.
   \item We propose a piece-wise rectangling scheme to reduce the distortion while preserving as much as possible image content when cropping the panorama to generate new photos.
\end{itemize}

 \section{RELATED WORK}
In this section, we briefly review the most related works.

\textbf{image stitching}.
Image stitching aims to create seamless and natural photo-mosaics. A comprehensive survey of image stitching algorithms is given in~\cite{journals/ftcgv/Szeliski06}. We only mention representative works in this section.
Brown et al.~\cite{journals/ijcv/BrownL07} proposed fully automatic panoramic image stitching, and align multiple images by a single homography. Their method is effective under assumption that camera only rotates around its optical center, images are shot from the same viewpoint and the scenes are nearly planar. However, for images shot by hand-held cameras always contain parallax, which limits the application of their method.
Given the limitation of single homography, Gao et al.~\cite{conf/CVPR/GaoKB11} proposed to use two homographies to perform nonlinear alignment, when the scene is modelled by dominant distant and ground planes. However, their method is only effective when there is no local perspective variations.

For better performance in image alignment, Zaragoza et al.~\cite{journals/pami/ZaragozaCTBS14} proposed as-projective-as-possible(APAP) warping based on Moving DLT, and can seamlessly align images with different projective models. Their method can achieve globally perspective, while allowing local non-projective deviations, thus can deal with some challenging cases. Now APAP~\cite{journals/pami/ZaragozaCTBS14}  has been widely applied for its excellent performance in image alignment. In this paper, we also apply APAP for image alignment as an initialization before optimization.
Based on  APAP~\cite{journals/pami/ZaragozaCTBS14}, researchers attempted to get more natural panorama. Lin et al.~\cite{conf/CVPR/LinPRA15} combined local homography and global similarity transformation to achieve more continuous and smooth stitching results. It provided stitched panorama with less visible parallax and perspective distortion.
Li et al.~\cite{conf/ICCV/LiY0Q15} proposed a dual-feature warping-based model by combining keypoints and line segment features. However, the 2D model proposed in this paper cannot handle large parallax and depth variation, and it is difficult to determine the line correspondences in images with large parallax.
For natural warping in stitching, Chang et al.~\cite{conf/cvpr/ChangSC14} proposed a parametric warp which combines projective and similarity transformation. By combining APAP~\cite{journals/pami/ZaragozaCTBS14}, their method can provide more accurate alignment, less distortion.
Chen et al.~\cite{conf/eccv/ChenC16} proposed natural image stitching with global similarity prior to reduce distortion while keep good alignment. To preserve global similarity, they further proposed schemes to select proper scale and rotation for more natural stitching results.

There are also methods focusing on the local alignment adjustment for eliminating stitching artifacts. To stitch images with large parallax, Zhang~\cite{conf/cvpr/ZhangL14a} proposed local stitching method, which is based on the observation that overlapping regions do not need to be aligned perfectly.
Lin et al.~\cite{conf/eccv/LinJCDL16} proposed a seam-guided local alignment, and optimal local alignment is guided by the seam estimation.
In their method, salient curve and line structures are preserved by local and non-local similarity constraint.
Very recently, Li et al.~\cite{journals/tmm/LiWLZZ18} proposed robust elastic warping for parallax-tolerant image stitching. To ensure a robust alignment, they proposed a Bayesian model to remove incorrect local matches.

However, all these above methods do not consider how to achieve better results in the display window. He et al.~\cite{journals/tog/HeC013} proposed a content-aware warping to produce rectangular images from stitched panorama.  Their method are effective to rectify irregular boundaries caused by projections and casual camera movements. However, their two-step warping strategy separates stitching and rectangling process, which can not ensure an optimal solution, and their method can not process scenes that are not completely captured.
Inspired by~\cite{journals/tog/HeC013}, We incorporate rectangling into the stitching framework, and construct global optimization to get rectangular panoramic images.
We also proposed solutions to deal with challenging cases, such as images that are not completely shot, and apply our method to panoramic video and selfie photography.

\textbf{video stitching}.
Compared with image stitching, video stitching is much more difficult, due to the camera motion, dynamic foreground and large parallax.
For static camera settings, such as multi-camera surveillance~\cite{journals/sensors/HeY16,journals/itiis/YinLWLZ14},  videos from different cameras are aligned only once, and the main challenge is to avoid ghosting and artifacts caused by moving objects.
For moving cameras with relative fixed positions, such as camera arrays fixed on the rig~\cite{journals/cgf/PerazziSZKWWG15}, cameras can be pre-calibrated for global stitching of videos, and spatia-temporally coherent warping, minimal distortion are the main challenges due to the motion and parallax.
Google streetview~\cite{journals/computer/AnguelovDFFLLOVW10} also applies moving camera arrays for street view capture and panorama generation.
To generate high-quality panorama videos, for videos captures by camera arrays fixed on a rig, Zhu et al.~\cite{journals/tip/ZhuLWZMLH18} proposed a realtime panorama video blending method.
Meng et al.~\cite{conf/mm/MengWL15} proposed multi-UAV surveillance system that supports real-time video stitching.
Recently, many researchers focus on stitching algorithm for videos shot by multiple hand-held cameras.
El-Saban et al.~\cite{conf/icip/El-SabanEKR11} proposed optimal seam selection blending for fast video stitching, however, they do not consider video stabilization.
Lin et al.~\cite{journals/cgf/LinLCZ16} firstly proposed robust framework stitch videos from moving hand-held cameras, which incorporates stabilization and stitching into a unified framework.
Guo et al. and Nei et al.~\cite{journals/tip/GuoLHZZG16,journals/tip/NieSZSL18} further improve the performance of  jointly video stabilization and stitching framework.
Their main contributions include: estimation of inter motions between cameras and intra motions in a video; common background identification for multiple input videos.
In this paper, we extend our content-preserving image stitching to videos that are captured from unstructured camera arrays\cite{journals/cgf/PerazziSZKWWG15}.


 \section{OVERVIEW}

Fig.~\ref{fig:pipeline} gives the pipeline of our content-preserving stitching.
The input to our approach is a number of images with content overlaps, and the goal is to obtain panorama images with regular boundaries by our content-preserving stitching.
The core of our approach is the unified image stitching and rectangling optimization, which contains following steps:

%Similar to~\cite{journals/tog/HeC013}, we also call this process "rectangling"~\cite{journals/tog/HeC013}, which contains following steps.
\textbf{Preprocessing}. 
In this step, we first calculate the image match graph using the method proposed in~\cite{journals/ijcv/BrownL07}, and those connected images are aligned to be panoramas. This automatic match process allows stitching with complex image overlaps.
For straight line and global feature preserving, we detect lines in all images using fast line segment detector~\cite{journals/pami/GioiJMR10}.

\textbf{Initial image stitching}. 
The goal of this step is to initialize our content-preserving stitching, and our regular boundary constraints are based on the analysis of warped meshes after stitching. The stitching strategy in this step is also applied in our global optimization which combines stitching and rectangling.
We apply APAP~\cite{journals/pami/ZaragozaCTBS14} for accurate feature alignment.
Inspired by~\cite{conf/eccv/ChenC16}, we also add a global similarity term for natural stitching with less distortion.

\textbf{Irregular boundary construction}.
In this step, we detect the irregular boundary by analyzing the meshes of warped images after the initial stitching.
We extract the contour of each warped mesh, and formulate the problem as a polygon boolean Union operation, which can be efficiently solved.
 We further determine the corners and boundaries in four directions.
 
 \textbf{Content-preserving image stitching}.
 In this step, we propose a global optimization which aims to generate panoramas with regular boundaries in the stitching framework.
 The optimization consists of the following constrains: feature alignment, shape preserving, straight lines preserving, global similarity preserving and regular boundary constraints.
With the optimized vertices, we further warp the mesh, and blend overlapped regions to generate panoramas.




\begin{figure*}[t] %% htbp
  \centering
  \includegraphics[width=1.0\textwidth]{flowchart}

  \caption{Pipeline of \emph{StereoPasting}. In the preprocessing step, we first select and triangulate the 2D foreground, then estimate the disparity map of the target scene. After that we edit the disparity map of the 2D foreground by painting strokes and blend it with the 3D background for depth-consistent composition. At last, the 2D foreground is warped and blended into the target image pair to get the composition results.} \label{fig:pipeline}
\end{figure*}

 \subsection{Initial image stitching}
 
 

\subsection{Irregular boundary construction}

\begin{figure}[t] %% htbp
  \centering
  \includegraphics[width=0.49\textwidth]{polybool}

  \caption{Pipeline of \emph{StereoPasting}. In the preprocessing step, we first select and triangulate the 2D foreground, then estimate the disparity map of the target scene. After that we edit the disparity map of the 2D foreground by painting strokes and blend it with the 3D background for depth-consistent composition. At last, the 2D foreground is warped and blended into the target image pair to get the composition results.} \label{fig:polybool}
\end{figure}

~\cite{journals/gandc/MartinezRF09}

\subsection{Content-preserving image stitching} 



 \section{RESULTS AND APPLICATIONS}

 \subsection{Results}

 \subsection{Applications}

 \subsubsection{Selfie expansion}

\subsubsection{Content-preserving Stitching}


 \section{CONCLUSION}



%


 %\begin{equation} \label{equ:brush_diffusion}
%\begin{aligned}
 %   E(u)=&\sum\limits_{p\in I} (w_{d}(p)(u(p)-d(p))^{2}+\\
  %  &\nabla \textbf{u}_{p}^{T} \textbf{w}_{p}\nabla\textbf{u}_{p})
%\end{aligned}
%\end{equation}

%where $d(p)$ refers to the values on the strokes, and $w_d(p)$ specifies the mask of the strokes.
%$\nabla \textbf{u}$ denotes the gradient of the disparity map $u$ along the x and y axis. $\textbf{w}_{p}$ refers to a 2x2 diagonal matrix whose diagonal elements are $w_{x}(p)$ and $w_{y}(p)$.

%\begin{equation}
%w_d(p)=\left\{
 %            \begin{array}{ll}
  %                  \infty & p \in strokes \\
   %                 0  & otherwise
   %          \end{array}
   %     \right.
%\end{equation}

% \begin{figure*}[t] %% htbp
 % \centering
 % \includegraphics[width=1.0\textwidth]{Figure1}

  %\caption{Pipeline of \emph{StereoPasting}. In the preprocessing step, we first select and triangulate the 2D foreground, then estimate the disparity map of the target scene. After that we edit the disparity map of the 2D foreground by painting strokes and blend it with the 3D background for depth-consistent composition. At last, the 2D foreground is warped and blended into the target image pair to get the composition results.} \label{fig:pipeline}
%\end{figure*}



% The very first letter is a 2 line initial drop letter followed
% by the rest of the first word in caps (small caps for compsoc).
%
% form to use if the first word consists of a single letter:
% \IEEEPARstart{A}{demo} file is ....
%
% form to use if you need the single drop letter followed by
% normal text (unknown if ever used by the IEEE):
% \IEEEPARstart{A}{}demo file is ....
%
% Some journals put the first two words in caps:
% \IEEEPARstart{T}{his demo} file is ....
%
% Here we have the typical use of a "T" for an initial drop letter
% and "HIS" in caps to complete the first word.



%\hfill mds
%\hfill August 26, 2015




% if have a single appendix:
%\appendix[Proof of the Zonklar Equations]
% or
%\appendix  % for no appendix heading
% do not use \section anymore after \appendix, only \section*
% is possibly needed

% use appendices with more than one appendix
% then use \section to start each appendix
% you must declare a \section before using any
% \subsection or using \label (\appendices by itself
% starts a section numbered zero.)
%


% use section* for acknowledgment
\ifCLASSOPTIONcompsoc
  % The Computer Society usually uses the plural form
  \section*{Acknowledgments}
The authors would like to thank...


% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi



% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://mirror.ctan.org/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
\bibliographystyle{IEEEtran}
\bibliography{tvcg}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)

%\begin{thebibliography}{1}

%\bibitem{IEEEhowto:kopka}
%H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
 % 0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.

%\end{thebibliography}

% biography section
%
% If you have an EPS/PDF photo (graphicx package needed) extra braces are
% needed around the contents of the optional argument to biography to prevent
% the LaTeX parser from getting confused when it sees the complicated
% \includegraphics command within an optional argument. (You could create
% your own custom macro containing the \includegraphics command to make things
% simpler here.)
%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{mshell}}]{Michael Shell}
% or if you just want to reserve a space for a photo:

%\begin{IEEEbiography}{Michael Shell}
%Biography text here.
%\end{IEEEbiography}

% if you will not have a photo at all:
%\begin{IEEEbiographynophoto}{John Doe}
%Biography text here.
%\end{IEEEbiographynophoto}

% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}



% that's all folks
\end{document}


>>>>>>> parent of 93a06e9... More edits on related work
